{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XTREME has 183 configurations\n"
     ]
    }
   ],
   "source": [
    "from datasets import get_dataset_config_names\n",
    "\n",
    "# Get subsets of XTREME multilingual dataset\n",
    "xtreme_subsets = get_dataset_config_names(\"xtreme\")\n",
    "print(f\"XTREME has {len(xtreme_subsets)} configurations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal here is to train a transformer for multilingual NER. We will use a subset of the XTREME dataset for this. It consists of Wikipedia articles in many languages with NER annotations. We specifically want to fine tune for German, French, Italian, and English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PAN-X.af', 'PAN-X.ar', 'PAN-X.bg']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panx_subsets = [s for s in xtreme_subsets if s.startswith(\"PAN\")]\n",
    "panx_subsets[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'langs'],\n",
       "        num_rows: 20000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'langs'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'langs'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "load_dataset(\"xtreme\", name=\"PAN-X.de\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a realistic Swiss corpus that includes German, French, Italian, and English\n",
    "# according to the spoken proportion.\n",
    "from collections import defaultdict\n",
    "from datasets import DatasetDict\n",
    "\n",
    "langs = [\"de\", \"fr\", \"it\", \"en\"]\n",
    "fracs = [\n",
    "    0.629,\n",
    "    0.229,\n",
    "    0.084,\n",
    "    0.059,\n",
    "]  # These percentages reflect the portion of the Swiss population who speak this language primarily.\n",
    "# Return a DatasetDict if a key doesn't exist\n",
    "panx_ch = defaultdict(DatasetDict)\n",
    "\n",
    "for lang, frac in zip(langs, fracs):\n",
    "    # Load monolingual corpus\n",
    "    ds = load_dataset(\"xtreme\", name=f\"PAN-X.{lang}\")\n",
    "    # Shuffle and downsample each split according to spoken proportion\n",
    "    for split in ds:\n",
    "        panx_ch[lang][split] = (\n",
    "            ds[split].shuffle(seed=0).select(range(int(frac * ds[split].num_rows)))\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>de</th>\n",
       "      <th>fr</th>\n",
       "      <th>it</th>\n",
       "      <th>en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Number of training examples</th>\n",
       "      <td>12580</td>\n",
       "      <td>4580</td>\n",
       "      <td>1680</td>\n",
       "      <td>1180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                de    fr    it    en\n",
       "Number of training examples  12580  4580  1680  1180"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(\n",
    "    {lang: [panx_ch[lang][\"train\"].num_rows] for lang in langs},\n",
    "    index=[\"Number of training examples\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just curious if there's a latin dataset\n",
    "[s for s in xtreme_subsets if \"la\" in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens: ['2.000', 'Einwohnern', 'an', 'der', 'Danziger', 'Bucht', 'in', 'der', 'polnischen', 'Woiwodschaft', 'Pommern', '.']\n",
      "ner_tags: [0, 0, 0, 0, 5, 6, 0, 0, 5, 5, 6, 0]\n",
      "langs: ['de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de']\n"
     ]
    }
   ],
   "source": [
    "# Inspect German examples\n",
    "element = panx_ch[\"de\"][\"train\"][0]\n",
    "for k, v in element.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens: Sequence(feature=Value(dtype='string', id=None), length=-1, id=None)\n",
      "ner_tags: Sequence(feature=ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'], id=None), length=-1, id=None)\n",
      "langs: Sequence(feature=Value(dtype='string', id=None), length=-1, id=None)\n"
     ]
    }
   ],
   "source": [
    "for k, v in panx_ch[\"de\"][\"train\"].features.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'], id=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = panx_ch[\"de\"][\"train\"].features[\"ner_tags\"].feature\n",
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tag_name(batch):\n",
    "    return {\"ner_tags_str\": [tags.int2str(idx) for idx in batch[\"ner_tags\"]]}\n",
    "\n",
    "\n",
    "pan_de = panx_ch[\"de\"].map(create_tag_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>2.000</td>\n",
       "      <td>Einwohnern</td>\n",
       "      <td>an</td>\n",
       "      <td>der</td>\n",
       "      <td>Danziger</td>\n",
       "      <td>Bucht</td>\n",
       "      <td>in</td>\n",
       "      <td>der</td>\n",
       "      <td>polnischen</td>\n",
       "      <td>Woiwodschaft</td>\n",
       "      <td>Pommern</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tags</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0           1   2    3         4      5   6    7           8   \\\n",
       "Tokens  2.000  Einwohnern  an  der  Danziger  Bucht  in  der  polnischen   \n",
       "Tags        O           O   O    O     B-LOC  I-LOC   O    O       B-LOC   \n",
       "\n",
       "                  9        10 11  \n",
       "Tokens  Woiwodschaft  Pommern  .  \n",
       "Tags           B-LOC    I-LOC  O  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "de_example = pan_de[\"train\"][0]\n",
    "pd.DataFrame(\n",
    "    [de_example[\"tokens\"], de_example[\"ner_tags_str\"]], index=[\"Tokens\", \"Tags\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOC</th>\n",
       "      <th>ORG</th>\n",
       "      <th>PER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>6186</td>\n",
       "      <td>5366</td>\n",
       "      <td>5810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validation</th>\n",
       "      <td>3172</td>\n",
       "      <td>2683</td>\n",
       "      <td>2893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>3180</td>\n",
       "      <td>2573</td>\n",
       "      <td>3071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             LOC   ORG   PER\n",
       "train       6186  5366  5810\n",
       "validation  3172  2683  2893\n",
       "test        3180  2573  3071"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate frequency of each tag across splits\n",
    "from collections import Counter\n",
    "\n",
    "split2freqs = defaultdict(Counter)\n",
    "for split, dataset in pan_de.items():\n",
    "    for row in dataset[\"ner_tags_str\"]:\n",
    "        for tag in row:\n",
    "            if tag.startswith(\"B\"):\n",
    "                tag_type = tag.split(\"-\")[1]\n",
    "                split2freqs[split][tag_type] += 1\n",
    "pd.DataFrame.from_dict(split2freqs, orient=\"index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multilingual transformer models are usually evaluated 3 ways:\n",
    "1. Fine tune on English and evaluate on each language's test set\n",
    "2. Fine tune and evaluate on monolingual test data to measure per language performance\n",
    "3. Fine tune on all the training data and evaluate on each language's test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the multilinguage transformer XLM-RoBERTa\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "bert_model_name = \"bert-base-cased\"\n",
    "xlmr_model_name = \"xlm-roberta-base\"\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained(bert_model_name)\n",
    "xlmr_tokenizer = AutoTokenizer.from_pretrained(xlmr_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Billy Holiday was an American jazz singer.\"\n",
    "bert_tokens = bert_tokenizer.tokenize(text)\n",
    "xlmr_tokens = xlmr_tokenizer.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Billy', 'Holiday', 'was', 'an', 'American', 'jazz', 'singer', '.']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁Billy', '▁Holiday', '▁was', '▁an', '▁American', '▁jazz', '▁sing', 'er', '.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xlmr_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes on custom transformers with Hugging Face\n",
    "Often time there will be a premade model and task class for your specific problem, e.g., if you wanted to classify sentences with BERT then you can use `BertForSequenceClassification`. But if this isnt the case, then you can create a custom model. Typically, models are a combination of a body - a usually pretrained transformer and tokenizer - and a head - the task specific component. Below is an example of a custom model for token classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from transformers import XLMRobertaConfig\n",
    "from transformers.modeling_outputs import TokenClassifierOutput\n",
    "from transformers.models.roberta.modeling_roberta import (\n",
    "    RobertaModel,\n",
    "    RobertaPreTrainedModel,\n",
    ")\n",
    "\n",
    "\n",
    "class XLMRobertaForTokenClassification(RobertaPreTrainedModel):\n",
    "    config_class = XLMRobertaConfig\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        # Load model body\n",
    "        self.roberta = RobertaModel(\n",
    "            config, add_pooling_layer=False\n",
    "        )  # Note that we set add_​pool⁠ing_layer=False to ensure all hidden states are returned and not only the one associated with the [CLS] token.\n",
    "        # Set up token classification head\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "        # Load and initialize weights\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        labels=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        # Use model body to get encoder representations\n",
    "        outputs = self.roberta(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            **kwargs\n",
    "        )\n",
    "        # Apply classifier to encoder representations\n",
    "        sequence_output = self.dropout(outputs[0])\n",
    "        logits = self.classifier(sequence_output)\n",
    "        # Calculate loss\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "        # Return model output object\n",
    "        return TokenClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "index2tag = {idx: tag for idx, tag in enumerate(tags.names)}\n",
    "tag2index = {tag: idx for idx, tag in enumerate(tags.names)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig\n",
    "\n",
    "xlmr_config = AutoConfig.from_pretrained(\n",
    "    xlmr_model_name, num_labels=tags.num_classes, id2label=index2tag, label2id=tag2index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XLMRobertaForTokenClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NB: The model requires 24gb of vram to load\n",
    "import torch\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "xlmr_model = XLMRobertaForTokenClassification.from_pretrained(\n",
    "    xlmr_model_name, config=xlmr_config\n",
    ")\n",
    "# xlmr_model.half()\n",
    "xlmr_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>▁Billy</td>\n",
       "      <td>▁Holiday</td>\n",
       "      <td>▁was</td>\n",
       "      <td>▁an</td>\n",
       "      <td>▁American</td>\n",
       "      <td>▁jazz</td>\n",
       "      <td>▁sing</td>\n",
       "      <td>er</td>\n",
       "      <td>.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Input IDs</th>\n",
       "      <td>0</td>\n",
       "      <td>134376</td>\n",
       "      <td>62827</td>\n",
       "      <td>509</td>\n",
       "      <td>142</td>\n",
       "      <td>15672</td>\n",
       "      <td>39644</td>\n",
       "      <td>5367</td>\n",
       "      <td>56</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0         1      2    3          4      5      6     7   8   \\\n",
       "Tokens     ▁Billy  ▁Holiday   ▁was  ▁an  ▁American  ▁jazz  ▁sing    er   .   \n",
       "Input IDs       0    134376  62827  509        142  15672  39644  5367  56   \n",
       "\n",
       "            9    10  \n",
       "Tokens     NaN  NaN  \n",
       "Input IDs  5.0  2.0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = xlmr_tokenizer.encode(text, return_tensors=\"pt\")\n",
    "pd.DataFrame([xlmr_tokens, input_ids[0].numpy()], index=[\"Tokens\", \"Input IDs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens in sequence: 9\n",
      "Shape of outputs: torch.Size([1, 11, 7])\n"
     ]
    }
   ],
   "source": [
    "outputs = xlmr_model(input_ids.to(device)).logits\n",
    "predictions = torch.argmax(outputs, dim=-1)\n",
    "print(f\"Number of tokens in sequence: {len(xlmr_tokens)}\")\n",
    "print(f\"Shape of outputs: {outputs.shape}\")  # [batch_size, num_tokens, num_tags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>▁Billy</td>\n",
       "      <td>▁Holiday</td>\n",
       "      <td>▁was</td>\n",
       "      <td>▁an</td>\n",
       "      <td>▁American</td>\n",
       "      <td>▁jazz</td>\n",
       "      <td>▁sing</td>\n",
       "      <td>er</td>\n",
       "      <td>.</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tags</th>\n",
       "      <td>B-LOC</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>B-LOC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1      2      3          4      5      6      7      8   \\\n",
       "Tokens  ▁Billy  ▁Holiday   ▁was    ▁an  ▁American  ▁jazz  ▁sing     er      .   \n",
       "Tags     B-LOC     I-PER  I-PER  B-ORG      B-ORG  B-ORG  B-ORG  B-ORG  B-ORG   \n",
       "\n",
       "           9      10  \n",
       "Tokens   None   None  \n",
       "Tags    B-ORG  B-LOC  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = [tags.names[p] for p in predictions[0].cpu().numpy()]\n",
    "pd.DataFrame([xlmr_tokens, preds], index=[\"Tokens\", \"Tags\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_text(text, tags, model, tokenizer):\n",
    "    # Get tokens with special characters\n",
    "    tokens = tokenizer(text).tokens()\n",
    "    # Encode the sequence into IDs\n",
    "    input_ids = xlmr_tokenizer(text, return_tensors=\"pt\").input_ids.to(device)\n",
    "    # Get predictions as distribution over 7 possible classes\n",
    "    outputs = model(input_ids)[0]\n",
    "    # Take argmax to get most likely class per token\n",
    "    predictions = torch.argmax(outputs, dim=2)\n",
    "    # Convert to dataframe\n",
    "    preds = [tags.names[p] for p in predictions[0].cpu().numpy()]\n",
    "    return pd.DataFrame([tokens, preds], index=[\"Tokens\", \"Tags\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before training, we need to tokenize the inputs and prepare the labels\n",
    "words, labels = de_example[\"tokens\"], de_example[\"ner_tags\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁2.000</td>\n",
       "      <td>▁Einwohner</td>\n",
       "      <td>n</td>\n",
       "      <td>▁an</td>\n",
       "      <td>▁der</td>\n",
       "      <td>▁Dan</td>\n",
       "      <td>zi</td>\n",
       "      <td>ger</td>\n",
       "      <td>▁Buch</td>\n",
       "      <td>...</td>\n",
       "      <td>▁Wo</td>\n",
       "      <td>i</td>\n",
       "      <td>wod</td>\n",
       "      <td>schaft</td>\n",
       "      <td>▁Po</td>\n",
       "      <td>mmer</td>\n",
       "      <td>n</td>\n",
       "      <td>▁</td>\n",
       "      <td>.</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0       1           2  3    4     5     6   7    8      9   ...   15  \\\n",
       "Tokens  <s>  ▁2.000  ▁Einwohner  n  ▁an  ▁der  ▁Dan  zi  ger  ▁Buch  ...  ▁Wo   \n",
       "\n",
       "       16   17      18   19    20 21 22 23    24  \n",
       "Tokens  i  wod  schaft  ▁Po  mmer  n  ▁  .  </s>  \n",
       "\n",
       "[1 rows x 25 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_input = xlmr_tokenizer(de_example[\"tokens\"], is_split_into_words=True)\n",
    "tokens = xlmr_tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n",
    "pd.DataFrame([tokens], index=[\"Tokens\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁2.000</td>\n",
       "      <td>▁Einwohner</td>\n",
       "      <td>n</td>\n",
       "      <td>▁an</td>\n",
       "      <td>▁der</td>\n",
       "      <td>▁Dan</td>\n",
       "      <td>zi</td>\n",
       "      <td>ger</td>\n",
       "      <td>▁Buch</td>\n",
       "      <td>...</td>\n",
       "      <td>▁Wo</td>\n",
       "      <td>i</td>\n",
       "      <td>wod</td>\n",
       "      <td>schaft</td>\n",
       "      <td>▁Po</td>\n",
       "      <td>mmer</td>\n",
       "      <td>n</td>\n",
       "      <td>▁</td>\n",
       "      <td>.</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word IDs</th>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0       1           2  3    4     5     6   7    8      9   ...  \\\n",
       "Tokens     <s>  ▁2.000  ▁Einwohner  n  ▁an  ▁der  ▁Dan  zi  ger  ▁Buch  ...   \n",
       "word IDs  None       0           1  1    2     3     4   4    4      5  ...   \n",
       "\n",
       "           15 16   17      18   19    20  21  22  23    24  \n",
       "Tokens    ▁Wo  i  wod  schaft  ▁Po  mmer   n   ▁   .  </s>  \n",
       "word IDs    9  9    9       9   10    10  10  11  11  None  \n",
       "\n",
       "[2 rows x 25 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_ids = tokenized_input.word_ids()\n",
    "pd.DataFrame([tokens, word_ids], index=[\"Tokens\", \"word IDs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁2.000</td>\n",
       "      <td>▁Einwohner</td>\n",
       "      <td>n</td>\n",
       "      <td>▁an</td>\n",
       "      <td>▁der</td>\n",
       "      <td>▁Dan</td>\n",
       "      <td>zi</td>\n",
       "      <td>ger</td>\n",
       "      <td>▁Buch</td>\n",
       "      <td>...</td>\n",
       "      <td>▁Wo</td>\n",
       "      <td>i</td>\n",
       "      <td>wod</td>\n",
       "      <td>schaft</td>\n",
       "      <td>▁Po</td>\n",
       "      <td>mmer</td>\n",
       "      <td>n</td>\n",
       "      <td>▁</td>\n",
       "      <td>.</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word IDs</th>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Label IDs</th>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>6</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Labels</th>\n",
       "      <td>IGN</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>IGN</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>...</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>O</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0       1           2     3    4     5      6     7     8   \\\n",
       "Tokens      <s>  ▁2.000  ▁Einwohner     n  ▁an  ▁der   ▁Dan    zi   ger   \n",
       "Word IDs   None       0           1     1    2     3      4     4     4   \n",
       "Label IDs  -100       0           0  -100    0     0      5  -100  -100   \n",
       "Labels      IGN       O           O   IGN    O     O  B-LOC   IGN   IGN   \n",
       "\n",
       "              9   ...     15    16    17      18     19    20    21  22    23  \\\n",
       "Tokens     ▁Buch  ...    ▁Wo     i   wod  schaft    ▁Po  mmer     n   ▁     .   \n",
       "Word IDs       5  ...      9     9     9       9     10    10    10  11    11   \n",
       "Label IDs      6  ...      5  -100  -100    -100      6  -100  -100   0  -100   \n",
       "Labels     I-LOC  ...  B-LOC   IGN   IGN     IGN  I-LOC   IGN   IGN   O   IGN   \n",
       "\n",
       "             24  \n",
       "Tokens     </s>  \n",
       "Word IDs   None  \n",
       "Label IDs  -100  \n",
       "Labels      IGN  \n",
       "\n",
       "[4 rows x 25 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set IDs for tokens we wish to mask\n",
    "previous_word_idx = None\n",
    "label_ids = []\n",
    "\n",
    "for word_idx in word_ids:\n",
    "    if word_idx is None or word_idx == previous_word_idx:\n",
    "        label_ids.append(\n",
    "            -100\n",
    "        )  # Choose -100 so that PyTorch cross-entropy loss ignores these tokens\n",
    "    elif word_idx != previous_word_idx:\n",
    "        label_ids.append(labels[word_idx])\n",
    "    previous_word_idx = word_idx\n",
    "\n",
    "labels = [index2tag[l] if l != -100 else \"IGN\" for l in label_ids]\n",
    "index = [\"Tokens\", \"Word IDs\", \"Label IDs\", \"Labels\"]\n",
    "\n",
    "pd.DataFrame([tokens, word_ids, label_ids, labels], index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap above in single function for aligning label ids with tokens\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = xlmr_tokenizer(\n",
    "        examples[\"tokens\"], truncation=True, is_split_into_words=True\n",
    "    )\n",
    "    labels = []\n",
    "    for idx, label in enumerate(examples[\"ner_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=idx)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None or word_idx == previous_word_idx:\n",
    "                label_ids.append(-100)\n",
    "            else:\n",
    "                label_ids.append(label[word_idx])\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f607e56599b48fe928b47849ddd36f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6290 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Encode datasets\n",
    "def encode_panx_dataset(corpus):\n",
    "    return corpus.map(\n",
    "        tokenize_and_align_labels,\n",
    "        batched=True,\n",
    "        remove_columns=[\"langs\", \"ner_tags\", \"tokens\"],\n",
    "    )\n",
    "\n",
    "\n",
    "panx_de_encoded = encode_panx_dataset(panx_ch[\"de\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to measure how well the model performs on the datasets. For token classification models, we can compute token-wise accuracy (as opposed to sequence-wise accuracy) using the `seqeval` library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        MISC       0.00      0.00      0.00         1\n",
      "         PER       1.00      1.00      1.00         1\n",
      "\n",
      "   micro avg       0.50      0.50      0.50         2\n",
      "   macro avg       0.50      0.50      0.50         2\n",
      "weighted avg       0.50      0.50      0.50         2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from seqeval.metrics import classification_report\n",
    "\n",
    "y_true = [[\"O\", \"O\", \"O\", \"B-MISC\", \"I-MISC\", \"I-MISC\", \"O\"], [\"B-PER\", \"I-PER\", \"O\"]]\n",
    "y_pred = [\n",
    "    [\"O\", \"O\", \"B-MISC\", \"I-MISC\", \"I-MISC\", \"I-MISC\", \"O\"],\n",
    "    [\"B-PER\", \"I-PER\", \"O\"],\n",
    "]\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def align_predictions(predictions, label_ids):\n",
    "    preds = np.argmax(predictions, axis=2)\n",
    "    batch_size, seq_len = preds.shape\n",
    "    labels_list, preds_list = [], []\n",
    "    for batch_idx in range(batch_size):\n",
    "        example_labels, example_preds = [], []\n",
    "        for seq_idx in range(seq_len):\n",
    "            # Ignore label IDs = -100\n",
    "            if label_ids[batch_idx, seq_idx] != -100:\n",
    "                example_labels.append(index2tag[label_ids[batch_idx][seq_idx]])\n",
    "                example_preds.append(index2tag[preds[batch_idx][seq_idx]])\n",
    "\n",
    "        labels_list.append(example_labels)\n",
    "        preds_list.append(example_preds)\n",
    "\n",
    "    return preds_list, labels_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tuning XLM-RoBERTa\n",
    "\n",
    "Now we can start training. We will first fine-tune the model on the German training data and then evaluate its zero shot efficacy on French, Italian, and English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "num_epochs = 3\n",
    "batch_size = 24\n",
    "logging_steps = len(panx_de_encoded[\"train\"]) // batch_size\n",
    "model_name = f\"{xlmr_model_name}-finetuned-panx-de\"\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=model_name,\n",
    "    log_level=\"error\",\n",
    "    num_train_epochs=num_epochs,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_steps=1e6,\n",
    "    weight_decay=0.01,\n",
    "    disable_tqdm=False,\n",
    "    logging_steps=logging_steps,\n",
    "    push_to_hub=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqeval.metrics import f1_score\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    y_pred, y_true = align_predictions(eval_pred.predictions, eval_pred.label_ids)\n",
    "    return {\"f1\": f1_score(y_true, y_pred)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(xlmr_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_init():\n",
    "    return XLMRobertaForTokenClassification.from_pretrained(\n",
    "        xlmr_model_name, config=xlmr_config\n",
    "    ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tyler/projects/personal/transformer-playground/venv/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "/home/tyler/projects/personal/transformer-playground/venv/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='396' max='396' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [396/396 01:27, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.167933</td>\n",
       "      <td>0.820612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.142453</td>\n",
       "      <td>0.838092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.137783</td>\n",
       "      <td>0.844654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=396, training_loss=0.20445918073557845, metrics={'train_runtime': 88.8462, 'train_samples_per_second': 424.779, 'train_steps_per_second': 4.457, 'total_flos': 1133538197223960.0, 'train_loss': 0.20445918073557845, 'epoch': 3.0})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model_init=model_init,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=panx_de_encoded[\"train\"],\n",
    "    eval_dataset=panx_de_encoded[\"validation\"],\n",
    "    tokenizer=xlmr_tokenizer,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁Jeff</td>\n",
       "      <td>▁De</td>\n",
       "      <td>an</td>\n",
       "      <td>▁ist</td>\n",
       "      <td>▁ein</td>\n",
       "      <td>▁Informati</td>\n",
       "      <td>ker</td>\n",
       "      <td>▁bei</td>\n",
       "      <td>▁Google</td>\n",
       "      <td>▁in</td>\n",
       "      <td>▁Kaliforni</td>\n",
       "      <td>en</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tags</th>\n",
       "      <td>O</td>\n",
       "      <td>B-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>O</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0      1      2      3     4     5           6    7     8        9   \\\n",
       "Tokens  <s>  ▁Jeff    ▁De     an  ▁ist  ▁ein  ▁Informati  ker  ▁bei  ▁Google   \n",
       "Tags      O  B-PER  I-PER  I-PER     O     O           O    O     O    B-ORG   \n",
       "\n",
       "         10          11     12    13  \n",
       "Tokens  ▁in  ▁Kaliforni     en  </s>  \n",
       "Tags      O       B-LOC  I-LOC     O  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_de = \"Jeff Dean ist ein Informatiker bei Google in Kalifornien\"\n",
    "tag_text(text_de, tags, trainer.model, xlmr_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import cross_entropy\n",
    "\n",
    "\n",
    "def forward_pass_with_label(batch):\n",
    "    # Convert dict of lists to list of dicts suitable for data collator\n",
    "    features = [dict(zip(batch, t)) for t in zip(*batch.values())]\n",
    "    # Pad inputs and labels, and put all tensors on device\n",
    "    batch = data_collator(features)\n",
    "    input_ids = batch[\"input_ids\"].to(device)\n",
    "    attention_mask = batch[\"attention_mask\"].to(device)\n",
    "    labels = batch[\"labels\"].to(device)\n",
    "    with torch.no_grad():\n",
    "        # Pass data through model\n",
    "        output = trainer.model(input_ids, attention_mask)\n",
    "        # logit.size: [batch_size, sequence_length, classes]\n",
    "        # Predict class with the largest logit value on classes axis\n",
    "        predicted_label = torch.argmax(output.logits, axis=-1).cpu().numpy()\n",
    "    # Calulate loss per token after flattening batch dimension with view\n",
    "    loss = cross_entropy(output.logits.view(-1, 7), labels.view(-1), reduction=\"none\")\n",
    "    # Unflatten batch dimension and convert to numpy array\n",
    "    loss = loss.view(len(input_ids), -1).cpu().numpy()\n",
    "\n",
    "    return {\"loss\": loss, \"predicted_label\": predicted_label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0b1b308b5db410c874c4385f182ddd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6290 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "valid_set = panx_de_encoded[\"validation\"]\n",
    "valid_set = valid_set.map(forward_pass_with_label, batched=True, batch_size=32)\n",
    "df = valid_set.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>labels</th>\n",
       "      <th>loss</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>input_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 10699, 11, 15, 16104, 1388, 2]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[IGN, B-ORG, IGN, I-ORG, I-ORG, I-ORG, IGN]</td>\n",
       "      <td>[0.0, 0.022340413, 0.0, 0.028917965, 0.0215935...</td>\n",
       "      <td>[I-ORG, B-ORG, I-ORG, I-ORG, I-ORG, I-ORG, I-ORG]</td>\n",
       "      <td>[&lt;s&gt;, ▁Ham, a, ▁(, ▁Unternehmen, ▁), &lt;/s&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0, 56530, 25216, 30121, 152385, 19229, 83982,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[IGN, O, IGN, IGN, IGN, IGN, B-ORG, IGN, IGN, ...</td>\n",
       "      <td>[0.0, 0.0010265801, 0.0, 0.0, 0.0, 0.0, 1.4925...</td>\n",
       "      <td>[O, O, O, O, O, O, B-LOC, I-LOC, I-LOC, I-LOC,...</td>\n",
       "      <td>[&lt;s&gt;, ▁WE, ITE, RL, EIT, UNG, ▁Luz, ky, j, ▁a,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0, 159093, 165, 38506, 122, 153080, 29088, 57...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[IGN, O, O, O, O, B-ORG, IGN, IGN, O, IGN, O, ...</td>\n",
       "      <td>[0.0, 0.0002888024, 0.00022122797, 0.000248639...</td>\n",
       "      <td>[O, O, O, O, O, B-ORG, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[&lt;s&gt;, ▁entdeckt, ▁und, ▁gehört, ▁der, ▁Spek, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0, 16459, 242, 5106, 6, 198715, 5106, 242, 2]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[IGN, O, O, O, B-LOC, IGN, O, O, IGN]</td>\n",
       "      <td>[0.0, 0.00039200252, 0.0003541081, 0.000371983...</td>\n",
       "      <td>[O, O, O, O, B-LOC, I-LOC, O, O, O]</td>\n",
       "      <td>[&lt;s&gt;, ▁**, ▁', ▁'', ▁, Bretagne, ▁'', ▁', &lt;/s&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0, 11022, 2315, 7418, 1079, 8186, 57242, 97, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[IGN, O, O, O, O, O, O, O, IGN, O, O, O, B-ORG...</td>\n",
       "      <td>[0.0, 0.00025436026, 0.0002591274, 0.000300839...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, B-ORG, I-...</td>\n",
       "      <td>[&lt;s&gt;, ▁Nach, ▁einem, ▁Jahr, ▁bei, ▁diesem, ▁Ve...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           input_ids  \\\n",
       "0                 [0, 10699, 11, 15, 16104, 1388, 2]   \n",
       "1  [0, 56530, 25216, 30121, 152385, 19229, 83982,...   \n",
       "2  [0, 159093, 165, 38506, 122, 153080, 29088, 57...   \n",
       "3     [0, 16459, 242, 5106, 6, 198715, 5106, 242, 2]   \n",
       "4  [0, 11022, 2315, 7418, 1079, 8186, 57242, 97, ...   \n",
       "\n",
       "                                      attention_mask  \\\n",
       "0                              [1, 1, 1, 1, 1, 1, 1]   \n",
       "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]   \n",
       "3                        [1, 1, 1, 1, 1, 1, 1, 1, 1]   \n",
       "4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "                                              labels  \\\n",
       "0        [IGN, B-ORG, IGN, I-ORG, I-ORG, I-ORG, IGN]   \n",
       "1  [IGN, O, IGN, IGN, IGN, IGN, B-ORG, IGN, IGN, ...   \n",
       "2  [IGN, O, O, O, O, B-ORG, IGN, IGN, O, IGN, O, ...   \n",
       "3              [IGN, O, O, O, B-LOC, IGN, O, O, IGN]   \n",
       "4  [IGN, O, O, O, O, O, O, O, IGN, O, O, O, B-ORG...   \n",
       "\n",
       "                                                loss  \\\n",
       "0  [0.0, 0.022340413, 0.0, 0.028917965, 0.0215935...   \n",
       "1  [0.0, 0.0010265801, 0.0, 0.0, 0.0, 0.0, 1.4925...   \n",
       "2  [0.0, 0.0002888024, 0.00022122797, 0.000248639...   \n",
       "3  [0.0, 0.00039200252, 0.0003541081, 0.000371983...   \n",
       "4  [0.0, 0.00025436026, 0.0002591274, 0.000300839...   \n",
       "\n",
       "                                     predicted_label  \\\n",
       "0  [I-ORG, B-ORG, I-ORG, I-ORG, I-ORG, I-ORG, I-ORG]   \n",
       "1  [O, O, O, O, O, O, B-LOC, I-LOC, I-LOC, I-LOC,...   \n",
       "2     [O, O, O, O, O, B-ORG, O, O, O, O, O, O, O, O]   \n",
       "3                [O, O, O, O, B-LOC, I-LOC, O, O, O]   \n",
       "4  [O, O, O, O, O, O, O, O, O, O, O, O, B-ORG, I-...   \n",
       "\n",
       "                                        input_tokens  \n",
       "0         [<s>, ▁Ham, a, ▁(, ▁Unternehmen, ▁), </s>]  \n",
       "1  [<s>, ▁WE, ITE, RL, EIT, UNG, ▁Luz, ky, j, ▁a,...  \n",
       "2  [<s>, ▁entdeckt, ▁und, ▁gehört, ▁der, ▁Spek, t...  \n",
       "3    [<s>, ▁**, ▁', ▁'', ▁, Bretagne, ▁'', ▁', </s>]  \n",
       "4  [<s>, ▁Nach, ▁einem, ▁Jahr, ▁bei, ▁diesem, ▁Ve...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index2tag[-100] = \"IGN\"\n",
    "df[\"input_tokens\"] = df[\"input_ids\"].apply(\n",
    "    lambda x: xlmr_tokenizer.convert_ids_to_tokens(x)\n",
    ")\n",
    "df[\"predicted_label\"] = df[\"predicted_label\"].apply(lambda x: [index2tag[i] for i in x])\n",
    "df[\"labels\"] = df[\"labels\"].apply(lambda x: [index2tag[i] for i in x])\n",
    "df[\"loss\"] = df.apply(lambda x: x[\"loss\"][: len(x[\"input_ids\"])], axis=1)\n",
    "df[\"predicted_label\"] = df.apply(\n",
    "    lambda x: x[\"predicted_label\"][: len(x[\"input_ids\"])], axis=1\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>labels</th>\n",
       "      <th>loss</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>input_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10699</td>\n",
       "      <td>1</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>0.02</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>▁Ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>0.03</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>▁(</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16104</td>\n",
       "      <td>1</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>0.02</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>▁Unternehmen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1388</td>\n",
       "      <td>1</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>0.03</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>▁)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56530</td>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "      <td>O</td>\n",
       "      <td>▁WE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>83982</td>\n",
       "      <td>1</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>1.49</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>▁Luz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>1.41</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>▁a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  input_ids attention_mask labels  loss predicted_label  input_tokens\n",
       "0     10699              1  B-ORG  0.02           B-ORG          ▁Ham\n",
       "0        15              1  I-ORG  0.03           I-ORG            ▁(\n",
       "0     16104              1  I-ORG  0.02           I-ORG  ▁Unternehmen\n",
       "0      1388              1  I-ORG  0.03           I-ORG            ▁)\n",
       "1     56530              1      O  0.00               O           ▁WE\n",
       "1     83982              1  B-ORG  1.49           B-LOC          ▁Luz\n",
       "1        10              1  I-ORG  1.41           I-LOC            ▁a"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tokens = df.apply(pd.Series.explode)\n",
    "df_tokens = df_tokens.query(\"labels != 'IGN'\")\n",
    "df_tokens[\"loss\"] = df_tokens[\"loss\"].astype(float).round(2)\n",
    "df_tokens.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>input_tokens</th>\n",
       "      <td>▁</td>\n",
       "      <td>▁der</td>\n",
       "      <td>▁von</td>\n",
       "      <td>▁in</td>\n",
       "      <td>▁und</td>\n",
       "      <td>▁/</td>\n",
       "      <td>▁(</td>\n",
       "      <td>▁)</td>\n",
       "      <td>▁''</td>\n",
       "      <td>▁A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6066</td>\n",
       "      <td>1388</td>\n",
       "      <td>808</td>\n",
       "      <td>989</td>\n",
       "      <td>1171</td>\n",
       "      <td>163</td>\n",
       "      <td>246</td>\n",
       "      <td>246</td>\n",
       "      <td>2898</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sum</th>\n",
       "      <td>209.14</td>\n",
       "      <td>124.07</td>\n",
       "      <td>119.57</td>\n",
       "      <td>110.68</td>\n",
       "      <td>84.36</td>\n",
       "      <td>82.02</td>\n",
       "      <td>81.65</td>\n",
       "      <td>79.83</td>\n",
       "      <td>70.22</td>\n",
       "      <td>55.69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0       1       2       3      4      5      6      7  \\\n",
       "input_tokens       ▁    ▁der    ▁von     ▁in   ▁und     ▁/     ▁(     ▁)   \n",
       "count           6066    1388     808     989   1171    163    246    246   \n",
       "mean            0.03    0.09    0.15    0.11   0.07    0.5   0.33   0.32   \n",
       "sum           209.14  124.07  119.57  110.68  84.36  82.02  81.65  79.83   \n",
       "\n",
       "                  8      9  \n",
       "input_tokens    ▁''     ▁A  \n",
       "count          2898    125  \n",
       "mean           0.02   0.45  \n",
       "sum           70.22  55.69  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    df_tokens.groupby(\"input_tokens\")[[\"loss\"]]\n",
    "    .agg([\"count\", \"mean\", \"sum\"])\n",
    "    .droplevel(level=0, axis=1)  # Get rid of multi-level columns\n",
    "    .sort_values(\"sum\", ascending=False)\n",
    "    .reset_index()\n",
    "    .round(2)\n",
    "    .head(10)\n",
    "    .T\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the high loss of white space - it occurs frequently but the mean suggests it's not problematic.\n",
    "\n",
    "Articles and prepositions have a higher mean loss but are generally handled well.\n",
    "\n",
    "/ and other similar characters have a suspiciously high loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <td>B-ORG</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>B-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2683</td>\n",
       "      <td>1462</td>\n",
       "      <td>3820</td>\n",
       "      <td>3172</td>\n",
       "      <td>2893</td>\n",
       "      <td>4139</td>\n",
       "      <td>43648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.63</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sum</th>\n",
       "      <td>1694.86</td>\n",
       "      <td>884.81</td>\n",
       "      <td>1862.35</td>\n",
       "      <td>1074.22</td>\n",
       "      <td>839.88</td>\n",
       "      <td>762.6</td>\n",
       "      <td>1346.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0       1        2        3       4      5       6\n",
       "labels    B-ORG   I-LOC    I-ORG    B-LOC   B-PER  I-PER       O\n",
       "count      2683    1462     3820     3172    2893   4139   43648\n",
       "mean       0.63    0.61     0.49     0.34    0.29   0.18    0.03\n",
       "sum     1694.86  884.81  1862.35  1074.22  839.88  762.6  1346.8"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    df_tokens.groupby(\"labels\")[[\"loss\"]]\n",
    "    .agg([\"count\", \"mean\", \"sum\"])\n",
    "    .droplevel(level=0, axis=1)\n",
    "    .sort_values(by=\"mean\", ascending=False)\n",
    "    .reset_index()\n",
    "    .round(2)\n",
    "    .T\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(y_preds, y_true, labels):\n",
    "    cm = confusion_matrix(y_true, y_preds, normalize=\"true\")\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "    disp.plot(cmap=\"Blues\", values_format=\".2f\", ax=ax, colorbar=False)\n",
    "    plt.title(\"Normalized confusion matrix\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_confusion_matrix(df_tokens[\"labels\"], df_tokens[\"predicted_label\"], tags.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>▁'</td>\n",
       "      <td>▁''</td>\n",
       "      <td>▁Τ</td>\n",
       "      <td>Κ</td>\n",
       "      <td>▁''</td>\n",
       "      <td>▁'</td>\n",
       "      <td>▁'</td>\n",
       "      <td>▁''</td>\n",
       "      <td>▁T</td>\n",
       "      <td>▁''</td>\n",
       "      <td>▁'</td>\n",
       "      <td>ri</td>\n",
       "      <td>▁''</td>\n",
       "      <td>▁'</td>\n",
       "      <td>k</td>\n",
       "      <td>▁''</td>\n",
       "      <td>▁'</td>\n",
       "      <td>ala</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>IGN</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preds</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>losses</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.48</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>9.61</td>\n",
       "      <td>6.48</td>\n",
       "      <td>8.50</td>\n",
       "      <td>8.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.41</td>\n",
       "      <td>9.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.94</td>\n",
       "      <td>9.29</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0     1      2      3     4     5      6      7      8      9   \\\n",
       "tokens    ▁'   ▁''     ▁Τ      Κ   ▁''    ▁'     ▁'    ▁''     ▁T    ▁''   \n",
       "labels     O     O      O    IGN     O     O  B-LOC  I-LOC  I-LOC  I-LOC   \n",
       "preds      O     O  B-ORG  I-ORG     O     O      O      O      O      O   \n",
       "losses  0.00  0.00   4.48   0.00  0.00  0.00  10.00   9.61   6.48   8.50   \n",
       "\n",
       "           10    11     12     13    14     15     16    17    18  \n",
       "tokens     ▁'    ri    ▁''     ▁'     k    ▁''     ▁'   ala  </s>  \n",
       "labels  I-LOC   IGN  I-LOC  I-LOC   IGN  I-LOC  I-LOC   IGN   IGN  \n",
       "preds       O     O      O      O     O      O      O     O     O  \n",
       "losses   8.70  0.00   8.41   9.03  0.00   8.94   9.29  0.00  0.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>▁''</td>\n",
       "      <td>8</td>\n",
       "      <td>.</td>\n",
       "      <td>▁Juli</td>\n",
       "      <td>▁''</td>\n",
       "      <td>▁:</td>\n",
       "      <td>▁Protest</td>\n",
       "      <td>camp</td>\n",
       "      <td>▁auf</td>\n",
       "      <td>▁dem</td>\n",
       "      <td>▁Gelände</td>\n",
       "      <td>▁der</td>\n",
       "      <td>▁Republika</td>\n",
       "      <td>n</td>\n",
       "      <td>ischen</td>\n",
       "      <td>▁Gar</td>\n",
       "      <td>de</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <td>B-ORG</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preds</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>losses</th>\n",
       "      <td>8.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.27</td>\n",
       "      <td>7.99</td>\n",
       "      <td>8.45</td>\n",
       "      <td>6.34</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.20</td>\n",
       "      <td>7.53</td>\n",
       "      <td>6.88</td>\n",
       "      <td>3.85</td>\n",
       "      <td>5.56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0     1     2      3      4      5         6     7      8      9   \\\n",
       "tokens    ▁''     8     .  ▁Juli    ▁''     ▁:  ▁Protest  camp   ▁auf   ▁dem   \n",
       "labels  B-ORG   IGN   IGN  I-ORG  I-ORG  I-ORG     I-ORG   IGN  I-ORG  I-ORG   \n",
       "preds       O     O     O      O      O      O         O     O      O      O   \n",
       "losses   8.85  0.00  0.00   4.27   7.99   8.45      6.34  0.00   7.20   7.53   \n",
       "\n",
       "              10     11          12     13      14     15     16    17  \n",
       "tokens  ▁Gelände   ▁der  ▁Republika      n  ischen   ▁Gar     de  </s>  \n",
       "labels     I-ORG  I-ORG       I-ORG    IGN     IGN  I-ORG    IGN   IGN  \n",
       "preds          O      O       B-ORG  I-ORG   I-ORG  I-ORG  I-ORG     O  \n",
       "losses      6.88   3.85        5.56   0.00    0.00   0.02   0.00  0.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>▁United</td>\n",
       "      <td>▁Nations</td>\n",
       "      <td>▁Multi</td>\n",
       "      <td>dimensional</td>\n",
       "      <td>▁Integra</td>\n",
       "      <td>ted</td>\n",
       "      <td>▁Stabil</td>\n",
       "      <td>ization</td>\n",
       "      <td>▁Mission</td>\n",
       "      <td>▁in</td>\n",
       "      <td>▁the</td>\n",
       "      <td>▁Central</td>\n",
       "      <td>▁African</td>\n",
       "      <td>▁Republic</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <td>B-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>IGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preds</th>\n",
       "      <td>B-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>losses</th>\n",
       "      <td>5.60</td>\n",
       "      <td>5.31</td>\n",
       "      <td>5.24</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.86</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.06</td>\n",
       "      <td>4.88</td>\n",
       "      <td>4.69</td>\n",
       "      <td>4.99</td>\n",
       "      <td>4.91</td>\n",
       "      <td>5.06</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1       2            3         4      5        6   \\\n",
       "tokens  ▁United  ▁Nations  ▁Multi  dimensional  ▁Integra    ted  ▁Stabil   \n",
       "labels    B-PER     I-PER   I-PER          IGN     I-PER    IGN    I-PER   \n",
       "preds     B-ORG     I-ORG   I-ORG        I-ORG     I-ORG  I-ORG    I-ORG   \n",
       "losses     5.60      5.31    5.24         0.00      5.00   0.00     4.86   \n",
       "\n",
       "             7         8      9      10        11        12         13     14  \n",
       "tokens  ization  ▁Mission    ▁in   ▁the  ▁Central  ▁African  ▁Republic   </s>  \n",
       "labels      IGN     I-PER  I-PER  I-PER     I-PER     I-PER      I-PER    IGN  \n",
       "preds     I-ORG     I-ORG  I-ORG  I-ORG     I-ORG     I-ORG      I-ORG  I-ORG  \n",
       "losses     0.00      5.06   4.88   4.69      4.99      4.91       5.06   0.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_samples(df):\n",
    "    for _, row in df.iterrows():\n",
    "        labels, preds, tokens, losses = [], [], [], []\n",
    "        for i, mask in enumerate(row[\"attention_mask\"]):\n",
    "            if i not in {0, len(row[\"attention_mask\"])}:\n",
    "                labels.append(row[\"labels\"][i])\n",
    "                preds.append(row[\"predicted_label\"][i])\n",
    "                tokens.append(row[\"input_tokens\"][i])\n",
    "                losses.append(f\"{row['loss'][i]:.2f}\")\n",
    "        df_tmp = pd.DataFrame(\n",
    "            {\"tokens\": tokens, \"labels\": labels, \"preds\": preds, \"losses\": losses}\n",
    "        ).T\n",
    "\n",
    "        yield df_tmp\n",
    "\n",
    "\n",
    "df[\"total_loss\"] = df[\"loss\"].apply(sum)\n",
    "df_tmp = df.sort_values(by=\"total_loss\", ascending=False).head(3)\n",
    "\n",
    "for sample in get_samples(df_tmp):\n",
    "    display(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the errors in the annotated data: United Nations is labeled a person not an org. PAN X utilizes machine-generated labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>▁Ham</td>\n",
       "      <td>a</td>\n",
       "      <td>▁(</td>\n",
       "      <td>▁Unternehmen</td>\n",
       "      <td>▁)</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <td>B-ORG</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>IGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preds</th>\n",
       "      <td>B-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>losses</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0      1      2             3      4      5\n",
       "tokens   ▁Ham      a     ▁(  ▁Unternehmen     ▁)   </s>\n",
       "labels  B-ORG    IGN  I-ORG         I-ORG  I-ORG    IGN\n",
       "preds   B-ORG  I-ORG  I-ORG         I-ORG  I-ORG  I-ORG\n",
       "losses   0.02   0.00   0.03          0.02   0.03   0.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>▁Kesk</td>\n",
       "      <td>kül</td>\n",
       "      <td>a</td>\n",
       "      <td>▁(</td>\n",
       "      <td>▁Mart</td>\n",
       "      <td>na</td>\n",
       "      <td>▁)</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <td>B-LOC</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>IGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preds</th>\n",
       "      <td>B-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>losses</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0      1      2      3      4      5      6      7\n",
       "tokens  ▁Kesk    kül      a     ▁(  ▁Mart     na     ▁)   </s>\n",
       "labels  B-LOC    IGN    IGN  I-LOC  I-LOC    IGN  I-LOC    IGN\n",
       "preds   B-LOC  I-LOC  I-LOC  I-LOC  I-LOC  I-LOC  I-LOC  I-LOC\n",
       "losses   0.03   0.00   0.00   0.04   0.04   0.00   0.04   0.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_tmp = df.loc[df[\"input_tokens\"].apply(lambda x: \"\\u2581(\" in x)].head(2)\n",
    "for sample in get_samples(df_tmp):\n",
    "    display(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Lingual Transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f1_score(trainer, dataset):\n",
    "    return trainer.predict(dataset).metrics[\"test_f1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tyler/projects/personal/transformer-playground/venv/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score of [de] model on [de] dataset: 0.85\n"
     ]
    }
   ],
   "source": [
    "f1_scores = defaultdict(dict)\n",
    "f1_scores[\"de\"][\"de\"] = get_f1_score(trainer, panx_de_encoded[\"test\"])\n",
    "print(f\"F1-score of [de] model on [de] dataset: {f1_scores['de']['de']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁Jeff</td>\n",
       "      <td>▁De</td>\n",
       "      <td>an</td>\n",
       "      <td>▁est</td>\n",
       "      <td>▁un</td>\n",
       "      <td>▁informatic</td>\n",
       "      <td>ien</td>\n",
       "      <td>▁chez</td>\n",
       "      <td>▁Google</td>\n",
       "      <td>▁en</td>\n",
       "      <td>▁Cali</td>\n",
       "      <td>for</td>\n",
       "      <td>nie</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tags</th>\n",
       "      <td>O</td>\n",
       "      <td>B-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>O</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0      1      2      3     4    5            6    7      8        9   \\\n",
       "Tokens  <s>  ▁Jeff    ▁De     an  ▁est  ▁un  ▁informatic  ien  ▁chez  ▁Google   \n",
       "Tags      O  B-PER  I-PER  I-PER     O    O            O    O      O    B-ORG   \n",
       "\n",
       "         10     11     12     13    14  \n",
       "Tokens  ▁en  ▁Cali    for    nie  </s>  \n",
       "Tags      O  B-LOC  I-LOC  I-LOC     O  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_fr = \"Jeff Dean est un informaticien chez Google en Californie\"\n",
    "tag_text(text_fr, tags, trainer.model, xlmr_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7620816b44b1436b9c5583e9e32bd7fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4580 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c060c91ca1fe46498a36e62f33410db5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2290 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eaf164cc34d4b7395e27979babdaa9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2290 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tyler/projects/personal/transformer-playground/venv/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score of [de] model on [fr] dataset: 0.693\n"
     ]
    }
   ],
   "source": [
    "def evaluate_lang_performance(lang, trainer):\n",
    "    panx_ds = encode_panx_dataset(panx_ch[lang])\n",
    "    return get_f1_score(trainer, panx_ds[\"test\"])\n",
    "\n",
    "\n",
    "f1_scores[\"de\"][\"fr\"] = evaluate_lang_performance(\"fr\", trainer)\n",
    "print(f\"F1-score of [de] model on [fr] dataset: {f1_scores['de']['fr']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7fdd81b4dbd48d7921d3fb31a729eab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d35f844d0cc49258347d798d5f62297",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/840 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9932343b116e47938769dc2a9b2872ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/840 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tyler/projects/personal/transformer-playground/venv/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score of [de] model on [it] dataset: 0.686\n"
     ]
    }
   ],
   "source": [
    "f1_scores[\"de\"][\"it\"] = evaluate_lang_performance(\"it\", trainer)\n",
    "print(f\"F1-score of [de] model on [it] dataset: {f1_scores['de']['it']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3069229fde1741af8a63ca304fa2c788",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1180 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60761a53a2084fffa6d0d094cf13be59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/590 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22efb8ce38c540fd8e9530af2ce14afd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/590 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tyler/projects/personal/transformer-playground/venv/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score of [de] model on [en] dataset: 0.602\n"
     ]
    }
   ],
   "source": [
    "f1_scores[\"de\"][\"en\"] = evaluate_lang_performance(\"en\", trainer)\n",
    "print(f\"F1-score of [de] model on [en] dataset: {f1_scores['de']['en']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and test on multiple subsets\n",
    "def train_on_subset(dataset, num_samples):\n",
    "    train_ds = dataset[\"train\"].shuffle(seed=42).select(range(num_samples))\n",
    "    valid_ds = dataset[\"validation\"]\n",
    "    test_ds = dataset[\"test\"]\n",
    "    training_args.logging_steps = len(train_ds) // batch_size\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model_init=model_init,\n",
    "        args=training_args,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics,\n",
    "        train_dataset=train_ds,\n",
    "        eval_dataset=valid_ds,\n",
    "        tokenizer=xlmr_tokenizer,\n",
    "    )\n",
    "    trainer.train()\n",
    "\n",
    "    f1_score = get_f1_score(trainer, test_ds)\n",
    "    return pd.DataFrame.from_dict(\n",
    "        {\"num_samples\": [len(train_ds)], \"f1_score\": [f1_score]}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 00:05, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.665674</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.449589</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.387054</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_samples</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>250</td>\n",
       "      <td>0.000646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_samples  f1_score\n",
       "0          250  0.000646"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panx_fr_encoded = encode_panx_dataset(panx_ch[\"fr\"])\n",
    "metrics_df = train_on_subset(panx_fr_encoded, 250)\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4063567/4217186130.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnum_samples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     metrics_df = metrics_df.append(\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mtrain_on_subset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpanx_fr_encoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     )\n",
      "\u001b[0;32m~/projects/personal/transformer-playground/venv/lib/python3.10/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6292\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6293\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6294\u001b[0m         ):\n\u001b[1;32m   6295\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6296\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "for num_samples in [500, 100, 2000, 4000]:\n",
    "    metrics_df = pd.concat([metrics_df, train_on_subset(panx_fr_encoded, num_samples)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
